#!/usr/bin/env python3

import streamlit as st
import sys
import os
import json
import yaml
import tempfile
import shutil
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional, Union
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from io import StringIO

# Add src to Python path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from core.application import DataIngestionApplication
from utils.config_manager import get_config_manager, ConfigurationError
from processors.schema_processor import SchemaProcessor

# Configure Streamlit page
st.set_page_config(
    page_title="Generic Data Ingestion Framework",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for enhanced styling
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    .main-header h1 {
        color: white;
        margin: 0;
    }
    .status-success {
        background-color: #d4edda;
        color: #155724;
        padding: 0.5rem 1rem;
        border-radius: 5px;
        border-left: 5px solid #28a745;
    }
    .status-error {
        background-color: #f8d7da;
        color: #721c24;
        padding: 0.5rem 1rem;
        border-radius: 5px;
        border-left: 5px solid #dc3545;
    }
    .status-warning {
        background-color: #fff3cd;
        color: #856404;
        padding: 0.5rem 1rem;
        border-radius: 5px;
        border-left: 5px solid #ffc107;
    }
    .info-box {
        background-color: #e7f3ff;
        padding: 1rem;
        border-radius: 5px;
        border-left: 5px solid #007bff;
        margin: 1rem 0;
    }
    .file-item {
        background-color: #f8f9fa;
        padding: 0.5rem;
        margin: 0.25rem 0;
        border-radius: 5px;
        border: 1px solid #dee2e6;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
def initialize_session_state():
    """Initialize all session state variables"""
    defaults = {
        'app_instance': None,
        'current_files': [],
        'processing_results': {},
        'db_config': None,
        'schema_data': {},
        'processing_logs': [],
        'presets': {},
        'file_statuses': {},
        'ingestion_history': []
    }
    
    for key, default_value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = default_value

def main():
    """Main application entry point"""
    initialize_session_state()
    
    # Header
    st.markdown('<div class="main-header"><h1>üìä Generic Data Ingestion Framework</h1><p>Comprehensive tool for semi-structured data processing and database loading</p></div>', unsafe_allow_html=True)
    
    # Sidebar configuration
    with st.sidebar:
        st.header("‚öôÔ∏è Configuration")
        
        # Database Configuration Section
        st.subheader("üóÑÔ∏è Database Setup")
        db_config = render_db_configuration()
        
        # Loading Strategy Section
        st.subheader("üìã Loading Strategy")
        loading_config = render_loading_strategy()
        
        # Preset Management
        st.subheader("üíæ Preset Management")
        render_preset_management()
        
        # Quick Stats
        if st.session_state.current_files:
            st.subheader("üìà Quick Stats")
            render_quick_stats()
    
    # Main content area with tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["üìÅ Upload", "üìã Schema", "üöÄ Ingest", "üìä Results", "üìù Logs"])
    
    with tab1:
        render_upload_tab()
    
    with tab2:
        render_schema_tab()
    
    with tab3:
        render_ingest_tab(db_config, loading_config)
    
    with tab4:
        render_results_tab()
    
    with tab5:
        render_logs_tab()

def render_db_configuration() -> Dict[str, Any]:
    """Render database configuration in sidebar"""
    st.write("üìã **Database Type**")
    db_type = st.selectbox("", ["postgresql", "mysql", "sqlite"], key="db_type_select")
    
    config_method = st.radio("Configuration Method", ["Direct Input", "Upload Config File", "Database URL"], key="config_method")
    
    db_config = None
    
    if config_method == "Direct Input":
        db_config = render_direct_db_config(db_type)
    elif config_method == "Upload Config File":
        db_config = render_config_file_upload()
    else:  # Database URL
        db_config = render_database_url_input()
    
    # Test connection button
    if db_config and st.button("üîç Test Connection", key="test_db_connection"):
        test_database_connection(db_config)
    
    return db_config

def render_direct_db_config(db_type: str) -> Optional[Dict[str, Any]]:
    """Render direct database configuration inputs"""
    config = {"db_type": db_type}
    
    if db_type == "sqlite":
        db_path = st.text_input("Database Path", value="data.sqlite", key="sqlite_path")
        config["database"] = db_path
    else:
        host = st.text_input("Host", value="localhost", key="db_host")
        port = st.number_input("Port", 
                               value=5432 if db_type == "postgresql" else 3306, 
                               key="db_port")
        database = st.text_input("Database Name", key="db_name")
        username = st.text_input("Username", key="db_username")
        password = st.text_input("Password", type="password", key="db_password")
        
        config.update({
            "host": host,
            "port": port,
            "database": database,
            "user": username,
            "password": password
        })
    
    # Connection options
    st.write("üîß **Connection Options**")
    config["connection_timeout"] = st.number_input("Connection Timeout (s)", value=30, key="conn_timeout")
    config["connection_pool_size"] = st.number_input("Pool Size", value=10, key="pool_size")
    
    return config if all(config.values()) else None

def render_config_file_upload() -> Optional[Dict[str, Any]]:
    """Render configuration file upload"""
    uploaded_file = st.file_uploader("Upload Config File", type=['json', 'yaml', 'yml'], key="config_file_upload")
    
    if uploaded_file:
        try:
            content = uploaded_file.read().decode('utf-8')
            if uploaded_file.name.endswith('.json'):
                config = json.loads(content)
            else:
                config = yaml.safe_load(content)
            
            st.success("‚úÖ Configuration file loaded successfully")
            st.json(config)
            return config
        except Exception as e:
            st.error(f"‚ùå Error loading config file: {str(e)}")
    
    return None

def render_database_url_input() -> Optional[Dict[str, Any]]:
    """Render database URL input"""
    db_url = st.text_input("Database URL", 
                          placeholder="postgresql://user:pass@host:port/db",
                          key="db_url_input")
    
    if db_url:
        try:
            config_manager = get_config_manager()
            config = config_manager.parse_database_url(db_url)
            st.success("‚úÖ Database URL parsed successfully")
            return config
        except Exception as e:
            st.error(f"‚ùå Error parsing database URL: {str(e)}")
    
    return None

def test_database_connection(db_config: Dict[str, Any]):
    """Test database connection"""
    try:
        app = DataIngestionApplication()
        connector = app.connector_factory.create_connector(
            db_type=db_config["db_type"],
            connection_params=db_config,
            use_pooling=False
        )
        
        # Test basic connection
        connector.test_connection()
        st.success("‚úÖ Database connection successful")
        
        # Show connection info
        conn_info = connector.get_connection_info()
        st.info(f"üìä Connected to {conn_info.get('db_type')} database: {conn_info.get('database')}")
        
    except Exception as e:
        st.error(f"‚ùå Connection failed: {str(e)}")

def render_loading_strategy() -> Dict[str, Any]:
    """Render loading strategy configuration"""
    strategy = st.selectbox("Strategy", ["append", "replace", "upsert"], key="load_strategy")
    table_name = st.text_input("Table Name", value="ingested_data", key="table_name")
    batch_size = st.number_input("Batch Size", value=1000, min_value=1, max_value=10000, key="batch_size")
    create_table = st.checkbox("Create Table if Missing", value=True, key="create_table")
    
    return {
        "strategy": strategy,
        "table_name": table_name,
        "batch_size": batch_size,
        "create_table": create_table
    }

def render_preset_management():
    """Render preset save/load functionality"""
    st.write("üíæ **Save Current Settings**")
    preset_name = st.text_input("Preset Name", key="preset_name_input")
    
    if st.button("üíæ Save Preset", key="save_preset") and preset_name:
        save_current_preset(preset_name)
    
    st.write("üìÅ **Load Preset**")
    if st.session_state.presets:
        selected_preset = st.selectbox("Available Presets", list(st.session_state.presets.keys()), key="preset_select")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("üìÅ Load", key="load_preset"):
                load_preset(selected_preset)
        with col2:
            if st.button("üóëÔ∏è Delete", key="delete_preset"):
                delete_preset(selected_preset)

def save_current_preset(name: str):
    """Save current configuration as preset"""
    preset = {
        "db_config": st.session_state.get("db_config"),
        "loading_strategy": {
            "strategy": st.session_state.get("load_strategy"),
            "table_name": st.session_state.get("table_name"),
            "batch_size": st.session_state.get("batch_size"),
            "create_table": st.session_state.get("create_table")
        },
        "saved_at": datetime.now().isoformat()
    }
    
    st.session_state.presets[name] = preset
    st.success(f"‚úÖ Preset '{name}' saved successfully")

def load_preset(name: str):
    """Load preset configuration"""
    if name in st.session_state.presets:
        preset = st.session_state.presets[name]
        # Update session state with preset values
        st.success(f"‚úÖ Preset '{name}' loaded successfully")
        st.rerun()

def delete_preset(name: str):
    """Delete preset"""
    if name in st.session_state.presets:
        del st.session_state.presets[name]
        st.success(f"‚úÖ Preset '{name}' deleted")
        st.rerun()

def render_quick_stats():
    """Render quick statistics in sidebar"""
    total_files = len(st.session_state.current_files)
    processed_files = len([f for f in st.session_state.file_statuses.values() if f.get("status") == "success"])
    
    st.metric("Total Files", total_files)
    st.metric("Processed", processed_files)
    
    if total_files > 0:
        progress = processed_files / total_files
        st.progress(progress)
        st.write(f"Progress: {progress*100:.1f}%")

def render_upload_tab():
    """Render the upload/file selection tab"""
    st.header("üìÅ Data Source Selection")
    
    # File input method selection
    input_method = st.radio("Select Input Method", ["Upload Files", "Select Directory"], key="input_method")
    
    if input_method == "Upload Files":
        render_file_upload()
    else:
        render_directory_selection()
    
    # Display currently selected files
    if st.session_state.current_files:
        st.subheader("üìã Selected Files")
        render_file_list()

def render_file_upload():
    """Render file upload interface"""
    st.subheader("üì§ Upload Data Files")
    
    uploaded_files = st.file_uploader(
        "Choose files to upload",
        type=['json', 'csv', 'parquet'],
        accept_multiple_files=True,
        key="file_uploader"
    )
    
    if uploaded_files:
        # Save uploaded files to temporary directory
        temp_dir = Path(tempfile.mkdtemp())
        file_paths = []
        
        for uploaded_file in uploaded_files:
            file_path = temp_dir / uploaded_file.name
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            file_paths.append(file_path)
        
        st.session_state.current_files = file_paths
        st.success(f"‚úÖ {len(uploaded_files)} files uploaded successfully")

def render_directory_selection():
    """Render directory selection interface"""
    st.subheader("üìÅ Select Directory")
    
    directory_path = st.text_input("Directory Path", placeholder="Enter directory path to scan", key="directory_input")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        recursive = st.checkbox("Recursive Scan", value=True, key="recursive_scan")
    with col2:
        file_types = st.multiselect("File Types", ["json", "csv", "parquet"], default=["json"], key="file_types")
    with col3:
        if st.button("üîç Scan Directory", key="scan_directory"):
            scan_directory(directory_path, file_types, recursive)

def scan_directory(directory_path: str, file_types: List[str], recursive: bool):
    """Scan directory for data files"""
    if not directory_path or not os.path.exists(directory_path):
        st.error("‚ùå Invalid directory path")
        return
    
    try:
        from scanners.file_scanner import FileScanner
        scanner = FileScanner(directory_path)
        discovered_files = scanner.discover_files(file_types=file_types, recursive=recursive)
        
        # Flatten the discovered files dict
        all_files = []
        for file_type, files in discovered_files.items():
            all_files.extend(files)
        
        st.session_state.current_files = all_files
        
        if all_files:
            st.success(f"‚úÖ Found {len(all_files)} files")
        else:
            st.warning("‚ö†Ô∏è No files found with the specified criteria")
            
    except Exception as e:
        st.error(f"‚ùå Error scanning directory: {str(e)}")

def render_file_list():
    """Render list of currently selected files"""
    for i, file_path in enumerate(st.session_state.current_files):
        status = st.session_state.file_statuses.get(str(file_path), {})
        
        with st.expander(f"üìÑ {Path(file_path).name}", expanded=False):
            col1, col2, col3 = st.columns([2, 1, 1])
            
            with col1:
                st.write(f"**Path:** {file_path}")
                if os.path.exists(file_path):
                    file_size = os.path.getsize(file_path) / 1024 / 1024  # MB
                    st.write(f"**Size:** {file_size:.2f} MB")
            
            with col2:
                if status.get("status") == "success":
                    st.markdown('<div class="status-success">‚úÖ Success</div>', unsafe_allow_html=True)
                elif status.get("status") == "error":
                    st.markdown('<div class="status-error">‚ùå Error</div>', unsafe_allow_html=True)
                elif status.get("status") == "processing":
                    st.markdown('<div class="status-warning">‚è≥ Processing</div>', unsafe_allow_html=True)
                else:
                    st.markdown('<div class="status-warning">‚è∏Ô∏è Pending</div>', unsafe_allow_html=True)
            
            with col3:
                if st.button(f"üóëÔ∏è Remove", key=f"remove_file_{i}"):
                    remove_file(i)
        
        # Show status details if available
        if status.get("error"):
            st.error(f"Error: {status['error']}")

def remove_file(index: int):
    """Remove file from current files list"""
    if 0 <= index < len(st.session_state.current_files):
        removed_file = st.session_state.current_files.pop(index)
        if str(removed_file) in st.session_state.file_statuses:
            del st.session_state.file_statuses[str(removed_file)]
        st.rerun()

def render_schema_tab():
    """Render schema handling tab"""
    st.header("üìã Schema Management")
    
    if not st.session_state.current_files:
        st.info("‚ÑπÔ∏è Please select files in the Upload tab first")
        return
    
    # Schema validation settings
    col1, col2, col3 = st.columns(3)
    with col1:
        validate_schemas = st.checkbox("Enable Schema Validation", value=True, key="validate_schemas")
    with col2:
        generate_flat = st.checkbox("Generate Flat Versions", value=True, key="generate_flat")
    with col3:
        if st.button("üîç Preview Schemas", key="preview_schemas"):
            preview_file_schemas()
    
    # Schema preview and modification
    if st.session_state.schema_data:
        render_schema_preview()

def preview_file_schemas():
    """Preview schemas of selected files"""
    try:
        schema_processor = SchemaProcessor()
        st.session_state.schema_data = {}
        
        for file_path in st.session_state.current_files[:5]:  # Limit to first 5 files
            if Path(file_path).suffix.lower() == '.json':
                try:
                    with open(file_path, 'r') as f:
                        data = json.load(f)
                    
                    schema = schema_processor.infer_schema(data if isinstance(data, list) else [data])
                    st.session_state.schema_data[str(file_path)] = schema
                    
                except Exception as e:
                    st.error(f"Error processing {Path(file_path).name}: {str(e)}")
        
        st.success(f"‚úÖ Schema preview generated for {len(st.session_state.schema_data)} files")
        
    except Exception as e:
        st.error(f"‚ùå Error previewing schemas: {str(e)}")

def render_schema_preview():
    """Render schema preview and editing interface"""
    st.subheader("üìä Schema Preview")
    
    for file_path, schema in st.session_state.schema_data.items():
        with st.expander(f"üìÑ {Path(file_path).name} Schema", expanded=False):
            if schema and 'fields' in schema:
                # Display schema as editable table
                schema_df = pd.DataFrame(schema['fields'])
                
                # Add column type override functionality
                st.write("**Column Types:**")
                for idx, field in enumerate(schema['fields']):
                    col1, col2, col3 = st.columns([2, 2, 1])
                    with col1:
                        st.write(f"**{field.get('name', 'Unknown')}**")
                    with col2:
                        new_type = st.selectbox(
                            "Type",
                            ["string", "integer", "float", "boolean", "array", "object"],
                            index=["string", "integer", "float", "boolean", "array", "object"].index(field.get('type', 'string')),
                            key=f"type_override_{file_path}_{idx}"
                        )
                        schema['fields'][idx]['type'] = new_type
                    with col3:
                        nullable = st.checkbox("Nullable", value=field.get('nullable', True), key=f"nullable_{file_path}_{idx}")
                        schema['fields'][idx]['nullable'] = nullable
            else:
                st.warning("‚ö†Ô∏è No schema information available")

def render_ingest_tab(db_config: Optional[Dict[str, Any]], loading_config: Dict[str, Any]):
    """Render data ingestion tab"""
    st.header("üöÄ Data Ingestion")
    
    if not st.session_state.current_files:
        st.info("‚ÑπÔ∏è Please select files in the Upload tab first")
        return
    
    # Ingestion settings summary
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìã Ingestion Summary")
        st.write(f"**Files to Process:** {len(st.session_state.current_files)}")
        st.write(f"**Validation:** {'Enabled' if st.session_state.get('validate_schemas', True) else 'Disabled'}")
        st.write(f"**Flat Versions:** {'Enabled' if st.session_state.get('generate_flat', True) else 'Disabled'}")
    
    with col2:
        if db_config:
            st.subheader("üóÑÔ∏è Database Target")
            st.write(f"**Type:** {db_config.get('db_type', 'Unknown')}")
            st.write(f"**Database:** {db_config.get('database', 'Unknown')}")
            st.write(f"**Table:** {loading_config.get('table_name', 'ingested_data')}")
            st.write(f"**Strategy:** {loading_config.get('strategy', 'append')}")
        else:
            st.warning("‚ö†Ô∏è No database configuration found")
    
    st.divider()
    
    # Ingestion controls
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if st.button("üîç Dry Run", key="dry_run_btn", type="secondary"):
            run_ingestion(dry_run=True, db_config=db_config, loading_config=loading_config)
    
    with col2:
        if st.button("üöÄ Start Ingestion", key="start_ingestion_btn", type="primary"):
            run_ingestion(dry_run=False, db_config=db_config, loading_config=loading_config)
    
    with col3:
        if st.button("‚èπÔ∏è Stop", key="stop_ingestion_btn"):
            st.warning("‚èπÔ∏è Ingestion stopped (feature coming soon)")
    
    with col4:
        if st.button("üîÑ Reset", key="reset_ingestion_btn"):
            reset_ingestion_state()

def run_ingestion(dry_run: bool = False, db_config: Optional[Dict[str, Any]] = None, loading_config: Dict[str, Any] = None):
    """Run the data ingestion process"""
    if not st.session_state.current_files:
        st.error("‚ùå No files selected for ingestion")
        return
    
    try:
        # Initialize the application
        app = DataIngestionApplication()
        
        # Create temporary output directory
        output_dir = Path(tempfile.mkdtemp())
        
        # Prepare file groups by type
        file_groups = {"json": [], "csv": [], "parquet": []}
        for file_path in st.session_state.current_files:
            suffix = Path(file_path).suffix.lower().lstrip('.')
            if suffix in file_groups:
                file_groups[suffix].append(Path(file_path))
        
        # Show progress
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # Process files
        total_files = len(st.session_state.current_files)
        processed_count = 0
        
        st.session_state.processing_results = {}
        st.session_state.processing_logs = []
        
        for i, file_path in enumerate(st.session_state.current_files):
            status_text.text(f"Processing {Path(file_path).name}...")
            st.session_state.file_statuses[str(file_path)] = {"status": "processing"}
            
            try:
                # Process individual file (simplified for demo)
                if not dry_run:
                    # Here you would call the actual processing logic
                    pass
                
                st.session_state.file_statuses[str(file_path)] = {"status": "success"}
                processed_count += 1
                
            except Exception as e:
                st.session_state.file_statuses[str(file_path)] = {"status": "error", "error": str(e)}
            
            # Update progress
            progress = (i + 1) / total_files
            progress_bar.progress(progress)
        
        # Database loading if not dry run and db_config exists
        if not dry_run and db_config and processed_count > 0:
            status_text.text("Loading data to database...")
            try:
                # Database loading logic would go here
                st.session_state.processing_logs.append("‚úÖ Database loading completed")
            except Exception as e:
                st.session_state.processing_logs.append(f"‚ùå Database loading failed: {str(e)}")
        
        # Final status
        if dry_run:
            st.success(f"‚úÖ Dry run completed. {processed_count}/{total_files} files would be processed.")
        else:
            st.success(f"‚úÖ Ingestion completed. {processed_count}/{total_files} files processed successfully.")
        
        progress_bar.progress(1.0)
        status_text.text("Processing complete!")
        
        # Add to history
        st.session_state.ingestion_history.append({
            "timestamp": datetime.now().isoformat(),
            "type": "Dry Run" if dry_run else "Full Ingestion",
            "files_processed": processed_count,
            "total_files": total_files,
            "success": True
        })
        
    except Exception as e:
        st.error(f"‚ùå Ingestion failed: {str(e)}")
        st.session_state.ingestion_history.append({
            "timestamp": datetime.now().isoformat(),
            "type": "Dry Run" if dry_run else "Full Ingestion",
            "files_processed": 0,
            "total_files": total_files,
            "success": False,
            "error": str(e)
        })

def reset_ingestion_state():
    """Reset ingestion state"""
    st.session_state.file_statuses = {}
    st.session_state.processing_results = {}
    st.session_state.processing_logs = []
    st.success("‚úÖ Ingestion state reset")
    st.rerun()

def render_results_tab():
    """Render results and analytics tab"""
    st.header("üìä Results & Analytics")
    
    if not st.session_state.file_statuses and not st.session_state.ingestion_history:
        st.info("‚ÑπÔ∏è No processing results available. Run ingestion first.")
        return
    
    # Processing Summary
    if st.session_state.file_statuses:
        render_processing_summary()
    
    st.divider()
    
    # Ingestion History
    if st.session_state.ingestion_history:
        render_ingestion_history()
    
    st.divider()
    
    # Performance Metrics (placeholder)
    render_performance_metrics()

def render_processing_summary():
    """Render processing summary with charts"""
    st.subheader("üìà Processing Summary")
    
    # Calculate status counts
    status_counts = {"success": 0, "error": 0, "processing": 0, "pending": 0}
    for status_info in st.session_state.file_statuses.values():
        status = status_info.get("status", "pending")
        status_counts[status] += 1
    
    # Display metrics
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("‚úÖ Success", status_counts["success"])
    with col2:
        st.metric("‚ùå Errors", status_counts["error"])
    with col3:
        st.metric("‚è≥ Processing", status_counts["processing"])
    with col4:
        st.metric("‚è∏Ô∏è Pending", status_counts["pending"])
    
    # Status distribution chart
    if any(status_counts.values()):
        fig = px.pie(
            values=list(status_counts.values()),
            names=list(status_counts.keys()),
            title="File Processing Status Distribution",
            color_discrete_map={
                "success": "#28a745",
                "error": "#dc3545",
                "processing": "#ffc107",
                "pending": "#6c757d"
            }
        )
        st.plotly_chart(fig, use_container_width=True)

def render_ingestion_history():
    """Render ingestion history"""
    st.subheader("üìú Ingestion History")
    
    history_df = pd.DataFrame(st.session_state.ingestion_history)
    if not history_df.empty:
        history_df['timestamp'] = pd.to_datetime(history_df['timestamp'])
        history_df = history_df.sort_values('timestamp', ascending=False)
        
        # Display as table
        st.dataframe(history_df, use_container_width=True)
        
        # Success rate over time
        if len(history_df) > 1:
            fig = px.line(
                history_df,
                x='timestamp',
                y='files_processed',
                title='Files Processed Over Time',
                markers=True
            )
            st.plotly_chart(fig, use_container_width=True)

def render_performance_metrics():
    """Render performance metrics (placeholder)"""
    st.subheader("‚ö° Performance Metrics")
    
    # Placeholder metrics
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Avg Processing Time", "2.3s", delta="0.1s")
    with col2:
        st.metric("Records/Second", "434", delta="12")
    with col3:
        st.metric("Memory Usage", "45MB", delta="2MB")
    
    # Placeholder chart
    dates = pd.date_range(start='2024-01-01', periods=30, freq='D')
    performance_data = pd.DataFrame({
        'date': dates,
        'processing_time': np.random.normal(2.3, 0.5, 30),
        'records_per_second': np.random.normal(434, 50, 30)
    })
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=performance_data['date'],
        y=performance_data['processing_time'],
        mode='lines+markers',
        name='Processing Time (s)',
        yaxis='y'
    ))
    fig.add_trace(go.Scatter(
        x=performance_data['date'],
        y=performance_data['records_per_second'],
        mode='lines+markers',
        name='Records/Second',
        yaxis='y2'
    ))
    
    fig.update_layout(
        title='Performance Trends',
        xaxis_title='Date',
        yaxis=dict(title='Processing Time (s)', side='left'),
        yaxis2=dict(title='Records/Second', side='right', overlaying='y'),
        hovermode='x unified'
    )
    
    st.plotly_chart(fig, use_container_width=True)

def render_logs_tab():
    """Render logs and detailed information tab"""
    st.header("üìù Logs & Details")
    
    # Log level filter
    log_levels = st.multiselect("Filter Log Levels", ["DEBUG", "INFO", "WARNING", "ERROR"], default=["INFO", "WARNING", "ERROR"], key="log_level_filter")
    
    # Real-time logs section
    st.subheader("üìä Processing Logs")
    
    if st.session_state.processing_logs:
        for log_entry in st.session_state.processing_logs[-50:]:  # Show last 50 entries
            if any(level in log_entry for level in log_levels):
                if "‚úÖ" in log_entry:
                    st.success(log_entry)
                elif "‚ùå" in log_entry:
                    st.error(log_entry)
                elif "‚ö†Ô∏è" in log_entry:
                    st.warning(log_entry)
                else:
                    st.info(log_entry)
    else:
        st.info("‚ÑπÔ∏è No processing logs available")
    
    st.divider()
    
    # File-level details
    st.subheader("üìÑ File Processing Details")
    
    if st.session_state.file_statuses:
        for file_path, status_info in st.session_state.file_statuses.items():
            with st.expander(f"üìÑ {Path(file_path).name}", expanded=False):
                st.json(status_info)
    
    st.divider()
    
    # System information
    st.subheader("üñ•Ô∏è System Information")
    
    col1, col2 = st.columns(2)
    with col1:
        st.write("**Python Version:**", sys.version.split()[0])
        st.write("**Platform:**", sys.platform)
        st.write("**Current Directory:**", str(Path.cwd()))
    
    with col2:
        st.write("**Session State Keys:**", len(st.session_state.keys()))
        st.write("**Active Files:**", len(st.session_state.current_files))
        st.write("**Processed Files:**", len(st.session_state.file_statuses))
    
    # Clear logs button
    if st.button("üóëÔ∏è Clear Logs", key="clear_logs_btn"):
        st.session_state.processing_logs = []
        st.session_state.file_statuses = {}
        st.success("‚úÖ Logs cleared")
        st.rerun()

if __name__ == "__main__":
    # Add numpy import for performance metrics
    try:
        import numpy as np
    except ImportError:
        st.error("NumPy is required for performance metrics. Please install it with: pip install numpy")
        st.stop()
    
    main()